BeyondChats – Blog Enhancement System Based on AI Technology

This is a project developed within the BeyondChats – Full Stack Web Developer Intern challenge.

It showcases the complete workflow of blog post scraping, AI-assisted improvement, and the presentation of original as well as enhanced blog posts through an intuitive UI.

## Live Demo

Frontend Live Link: https://blog-scrap.onrender.com

You can:
    View

Original articles scraped via Google News

AI-supported (updated) articles

Reference Links used for enhancement

????️ Tech Stack

Backend

Node.js

Express.js

MongoDB

Cheerio (Web Scraping

SearchAPI (Google results)

Google Gemini AI (Content Enhancement)

Front End

React.js

React Router

Axios

"React Markdown": used to display content generated by AI.

## Project Features

The oldest articles from the BeyondChats blogs }

Stores the articles in a MongoDB database.

Supports CRUD operations fully

Conducts Google searches on top-ranked articles that are related to

Scrapes reference content dynamically (with fall-back logic)

Applies Gemini AI technology to restructure articles into an organized and SEO-optimized manner Shows Original and Updated Articles in a clean UI Handling Real World Errors (Blocked Sites, Weak References)

## Local Setup Instructions
1️. Clone the Repository
git clone (https://github.com/LakshayRahal/beyond_scrap.git)
cd beyond_scrap

2️. Backend Setup
cd server
npm install


Create a .env file inside server/:

PORT=5000
MONGO_URI=your_mongodb_connection_string
SERP_API_KEY=your_searchapi_key
GEMINI_API_KEY=your_gemini_api_key


Start backend server:

npm run dev


Backend will run at:

http://localhost:5000

3️. Frontend Setup
cd frontend
npm install
npm run dev


Frontend will run at:

http://localhost:5173

### Data Flow / Architecture Diagram
┌────────────────────┐
│ BeyondChats Blogs  │
└─────────┬──────────┘
          │ (Scraping)
          ▼
┌────────────────────┐
│   Backend (Node)   │
│  - Cheerio         │
│  - Express APIs    │
└─────────┬──────────┘
          │
          ▼
┌────────────────────┐
│     MongoDB        │
│ (Original Articles)│
└─────────┬──────────┘
          │
          ▼
┌────────────────────┐
│  SearchAPI (Google)│
│  - Fetch top links │
└─────────┬──────────┘
          │
          ▼
┌────────────────────┐
│ Reference Scraper  │
│ (Multiple fallback)│
└─────────┬──────────┘
          │
          ▼
┌────────────────────┐
│   Gemini AI        │
│ (Rewrite Article)  │
└─────────┬──────────┘
          │
          ▼
┌────────────────────┐
│ MongoDB            │
│ (Updated Articles) │
└─────────┬──────────┘
          │
          ▼
┌────────────────────┐
│ React Frontend     │
│ (Display UI)       │
└────────────────────┘

### API Endpoints (Backend)
Articles CRUD

GET /api/articles – Fetch all articles

GET /api/articles/:id – Fetch article by ID

POST /api/articles – Create article

PUT /api/articles/:id – Update article

DELETE /api/articles/:id – Delete article

Automation

POST /api/automation/scrape-beyondchats – Scrape original articles

POST /api/automation/run-ai-update – Run AI enhancement pipeline

### Key Implementation Highlights

Dynamic reference selection: keeps trying Google results until 2 valid references are found

Graceful failure handling: skips blocked or weak sources

Markdown rendering: AI output rendered cleanly using React Markdown

Humanized UI: readable, blog-like article presentation

Scalable architecture: services separated (search, scraping, AI)

### Notes

Some external websites may block scraping (403).
The system handles this gracefully by skipping blocked sources.

Google Gemini outputs Markdown, which is rendered properly in the frontend